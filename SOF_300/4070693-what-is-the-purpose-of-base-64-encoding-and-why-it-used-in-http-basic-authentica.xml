<?xml version="1.0" encoding="utf-8"?>
<post><title>security - What is the purpose of base 64 encoding and why it used in HTTP Basic Authentication? - Stack Overflow</title><question><text><div class="post-text" itemprop="text">
<p>I don't get the Base64 encryption.</p>
<p>If one can decrypt a Base64 string, what is it's purpose?</p>
<p>Why is it being used for HTTP Basic auth?</p>
<p>It's like telling to someone my password is reversed into OLLEH.</p>
<p>People seeing OLLEH will know the original password was HELLO.</p>
</div></text><author><a href="/users/160823/omar">Omar</a></author><comments><comment><text><span class="comment-copy">related:  <a href="http://stackoverflow.com/questions/13661384/why-base64-in-basic-authentication">Why Base64 in Basic Authentication</a> and <a href="http://stackoverflow.com/questions/5597086/base-64-encoding-in-http-basic-auth">Base 64 encoding in HTTP Basic Auth</a></span></text><author><a class="comment-user" href="/users/99717/hawkeye-parker" title="2,118 reputation">Hawkeye Parker</a></author></comment><comment><text><span class="comment-copy"><a href="https://security.stackexchange.com/questions/29916/why-does-http-basic-authentication-encode-the-username-and-password-with-base64" title="why does http basic authentication encode the username and password with base64">security.stackexchange.com/questions/29916/…</a></span></text><author><a class="comment-user" href="/users/611007/n611x007" title="3,475 reputation">n611x007</a></author></comment><comment><text><span class="comment-copy">base64 is not an encryption, it's an encoding</span></text><author><a class="comment-user" href="/users/611007/n611x007" title="3,475 reputation">n611x007</a></author></comment></comments></question><answers><answer><text><div class="post-text" itemprop="text">
<p>Base64 is not encryption -- it's an encoding.  It's a way of representing binary data using only printable (text) characters.</p>
<p>See this paragraph from the <a href="http://en.wikipedia.org/wiki/Basic_access_authentication" rel="noreferrer">wikipedia page for HTTP Basic Authentication</a>:</p>
<blockquote>
<p>While encoding the user name and password with the Base64 algorithm typically makes them unreadable by the naked eye, they are as easily decoded as they are encoded. Security is not the intent of the encoding step. Rather, the intent of the encoding is to encode non-HTTP-compatible characters that may be in the user name or password into those that are HTTP-compatible.</p>
</blockquote>
</div></text><author><a href="/users/125871/matt-bridges">Matt Bridges</a></author><comments><comment><text><span class="comment-copy">Also, it seems that the relevant character encoding to get the 'binary data' from string, should be <a href="http://en.wikipedia.org/wiki/ISO/IEC_8859-1" rel="nofollow noreferrer">iso-8859-1</a>. (<a href="http://stackoverflow.com/questions/7242316/what-encoding-should-i-use-for-http-basic-authentication">source</a>)</span></text><author><a class="comment-user" href="/users/358197/myobis" title="764 reputation">Myobis</a></author></comment></comments></answer><answer><text><div class="post-text" itemprop="text">
<p>It's normally called base64 encoding, <em>not</em> encryption! The nice thing about base64 encoding is it allows you to represent (binary) data using only a limited, common-subset of the available characters, far more efficiently than just writing a string of 1s and 0s as ASCII for example.</p>
</div></text><author><a href="/users/168175/flexo">Flexo</a></author><comments><comment><text><span class="comment-copy">+1, but comparison to storing data in 1s,0s stream is too exaggerated. It is better to compare it to storing data in hex format. Because hex would only make <code>x2</code> more bytes than original stream, and 1s,0s - makes <code>x8</code> times more bytes. (And Base64 makes <code>x1.3</code> more data than original byte array). So sometimes it is acceptable to encode binary stream as hex string, doubling byte amount - for example just to store password hash in database.</span></text><author><a class="comment-user" href="/users/380331/agnius-vasiliauskas" title="5,576 reputation">Agnius Vasiliauskas</a></author></comment></comments></answer><answer><text><div class="post-text" itemprop="text">
<p><a href="http://en.wikipedia.org/wiki/Encryption" rel="noreferrer">En<em><strong>crypt</strong></em>ion</a> requires a key (string or algorithm) in order to decrypt; hence the "crypt" (root:<a href="http://en.wikipedia.org/wiki/Cryptography" rel="noreferrer">cryptography</a>)</p>
<p><a href="http://en.wikipedia.org/wiki/Encoding" rel="noreferrer">En<em><strong>cod</strong></em>ing</a> modifies/shifts/changes a character code into another.  In this case, usual bytes of data can now be easily represented and transported using HTTP.</p>
</div></text><author><a href="/users/183181/vol7ron">vol7ron</a></author><comments><comment><text><span class="comment-copy">Encryption just means "to render hidden" - key-based cryptography is a very recent invention. Enciphering is a form of encoding that has been used as encryption (though not by anyone over 12 years old for hundreds of years).</span></text><author><span class="comment-user">user23743</span></author></comment><comment><text><span class="comment-copy">Encryption in the vernacular is used to refer to recent modes of encryption, specifically computer encryption, which is key-based (public/private key).  While true, it is unnecessary to point out a literal definition of a dated word; otherwise, you'd be arguing the historical definition of many english words used today.  The vernacular (and sometimes colloquial) are what gives words context and thus definition.</span></text><author><a class="comment-user" href="/users/183181/vol7ron" title="18,420 reputation">vol7ron</a></author></comment><comment><text><span class="comment-copy">I don't think you sounded rude; I agree with your point about modern context. Words and definitions are constantly evolving. I think "encode" and "encrypt" definitely have two very distinct definitions in modern computing and your answer makes a good effort at summarizing the differences.</span></text><author><a class="comment-user" href="/users/770230/dan" title="2,705 reputation">Dan</a></author></comment><comment><text><span class="comment-copy">Base64 encoding is a form of obfuscation, which simply means to render unclear. For many applications, this is sufficient encryption where the goal is simply to mangle any clear text sent over a wire, for example.</span></text><author><a class="comment-user" href="/users/1048170/dominic-cerisano" title="717 reputation">Dominic Cerisano</a></author></comment><comment><text><span class="comment-copy">@DominicCerisano: No, base64 encoding does not count as encryption, and I hope you’re not using it to protect anything.</span></text><author><a class="comment-user" href="/users/707111/ryan" title="136,408 reputation">Ryan<span class="mod-flair" title="moderator">♦</span></a></author></comment><comment><text><span class="comment-copy">@ryan, it certainly is not strong encryption, and I agree it should only be considered in situations calling for weak encryption. Care for an example?</span></text><author><a class="comment-user" href="/users/1048170/dominic-cerisano" title="717 reputation">Dominic Cerisano</a></author></comment></comments></answer><answer><text><div class="post-text" itemprop="text">
<p>You might mean "Base 64 Encoding". Encryption is not the same as encoding.</p>
<p><a href="http://en.wikipedia.org/wiki/Encryption" rel="noreferrer">Wikipedia: Encryption</a></p>
</div></text><author><a href="/users/361460/andy">Andy</a></author><comments/></answer><answer><text><div class="post-text" itemprop="text">
<p>In everyday language, a “code” is something secret. In science and engineering, a code is simply an agreement, a set of rules, of how to write something.</p>
<p>That code <em>may</em> be secret. In that case, it’s called an encryption. But in general, a code is not secret. Take the genetic code. It simply states that our DNA is built from four different bases – <code>A</code>, <code>C</code>, <code>G</code> and <code>T</code> and that three bases taken together form one amino acid. There’s also a table of which three letters form which amino acid.</p>
<p>There’s nothing secret about this code.</p>
<p>Likewise, Base64 is not a secret code. Rather, it’s a code that allows storing data in six bits per character (thus there are 64 different entities, i.e. the “base” of the system is 64, just as the base of our decimal system is 10, since there are 10 different entities called “digits”).</p>
</div></text><author><a href="/users/1968/konrad-rudolph">Konrad Rudolph</a></author><comments/></answer><answer><text><div class="post-text" itemprop="text">
<p>Base-64 encoding is part of the MIME specifications. It provides a <strong>transport-safe</strong> encoding for data that won't get chewed on if/when it gets relayed through a host that uses a different encoding scheme than that used by the original client.</p>
<p>There are lots of different hosts out on the intertubes and you can't really assume support for anything other than 7-bit ASCII, without risking data loss/confusion.</p>
<p>IBM mainframes, for instance, use an encoding called EBCDIC (which comes in lots of different flavors). It's codepoints are completely different from the code points used by ASCII-based 'puters -- in ASCII, the letters A-Z are 0x41 - 0x5A; in EBCDIC the letters A - Z aren't even a contiguous range: the letters A-I live at 0xC1 - 0xC9, the letters J-R live at 0xD1 - 0xD9 and the letters S-Z live at 0xE2 - 0xE9.</p>
</div></text><author><a href="/users/467473/nicholas-carey">Nicholas Carey</a></author><comments/></answer></answers></post>