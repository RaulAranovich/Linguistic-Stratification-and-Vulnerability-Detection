<?xml version="1.0" encoding="utf-8"?>
<post><title>security - Docker and securing passwords - Stack Overflow</title><question><text><div class="post-text" itemprop="text">
<p>I've been experimenting with Docker recently on building some services to play around with and one thing that keeps nagging me has been putting passwords in a Dockerfile. I'm a developer so storing passwords in source feels like a punch in the face. Should this even be a concern? Are there any good conventions on how to handle passwords in Dockerfiles?</p>
</div></text><author><a href="/users/256618/mark-oconnor">Mark O'Connor</a></author><comments><comment><text><span class="comment-copy">There is an open issue on Github requesting for best practices regarding Docker and secrets, the issue is here: <a href="https://github.com/docker/docker/issues/13490" rel="nofollow noreferrer">github.com/docker/docker/issues/13490</a></span></text><author><a class="comment-user" href="/users/1046584/lu%c3%ads-bianchin" title="784 reputation">Lu√≠s Bianchin</a></author></comment></comments></question><answers><answer><text><div class="post-text" itemprop="text">
<p>Definitely it is a concern. Dockerfiles are commonly checked in to repositories and shared with other people. An alternative is to provide any credentials (usernames, passwords, tokens, anything sensitive) <a href="https://docs.docker.com/engine/reference/commandline/run/#/set-environment-variables-e-env-env-file" rel="noreferrer">as environment variables at runtime</a>. This is possible via the <code>-e</code> argument (for individual vars on the CLI) or <code>--env-file</code> argument (for multiple variables in a file) to <code>docker run</code>.</p>
<p>However, env vars are not particularly secure either. They are visible via <code>docker inspect</code>, and hence they are available to any user that can run <code>docker</code> commands. (Of course, any user that has access to <code>docker</code> on the host also <a href="https://docs.docker.com/engine/security/security/#/docker-daemon-attack-surface" rel="noreferrer">has root</a> anyway.)</p>
<p>My preferred pattern is to use a wrapper script as the <code>ENTRYPOINT</code> or <code>CMD</code>. The wrapper script can first import secrets from an outside location in to the container at run time, then execute the application, providing the secrets. The exact mechanics of this vary based on your run time environment. In AWS, you can use a combination of IAM roles, the <a href="https://aws.amazon.com/kms/" rel="noreferrer">Key Management Service</a>, and S3 to store encrypted secrets in an S3 bucket. Something like <a href="https://www.vaultproject.io/" rel="noreferrer">HashiCorp Vault</a> or <a href="https://github.com/fugue/credstash" rel="noreferrer">credstash</a> is another option.</p>
<p>AFAIK there is no optimal pattern for using sensitive data as part of the build process. In fact, I have an <a href="http://stackoverflow.com/questions/26005028/how-to-idiomatically-access-sensitive-data-when-building-a-docker-image">SO question</a> on this topic. You can use <a href="https://github.com/jwilder/docker-squash" rel="noreferrer">docker-squash</a> to remove layers from an image. But there's no native functionality in Docker for this purpose.</p>
<p>You may find shykes <a href="https://groups.google.com/forum/?fromgroups#%21topic/docker-user/FyCWLC38Ueg" rel="noreferrer">comments on config in containers</a> useful. </p>
</div></text><author><a href="/users/2430241/ben-whaley">Ben Whaley</a></author><comments><comment><text><span class="comment-copy">As noted in other comments there will be 2 layers (after ADD and after first RUN) that contain <code>.config</code> file.</span></text><author><a class="comment-user" href="/users/117220/petr-gladkikh" title="1,163 reputation">Petr Gladkikh</a></author></comment><comment><text><span class="comment-copy">Yer, env variables seems the best way to go. I've been looking at this in the context of TDDing Dockerfile development.</span></text><author><a class="comment-user" href="/users/491812/gnoll110" title="137 reputation">gnoll110</a></author></comment><comment><text><span class="comment-copy">I'm concerned that if your password is an env variable, it appears in <code>docker inspect</code>.</span></text><author><a class="comment-user" href="/users/7512/slim" title="19,569 reputation">slim</a></author></comment></comments></answer><answer><text><div class="post-text" itemprop="text">
<p>Our team avoids putting credentials in repositories, so that means they're not allowed in <code>Dockerfile</code>.  Our best practice within applications is to use creds from environment variables.</p>
<p>We solve for this using <code>docker-compose</code>.</p>
<p>Within <code>docker-compose.yml</code>, you can specify a file that contains the environment variables for the container:</p>
<pre><code> env_file:
- .env
</code></pre>
<p>Make sure to add <code>.env</code> to <code>.gitignore</code>, then set the credentials within the <code>.env</code> file like:</p>
<pre><code>SOME_USERNAME=myUser
SOME_PWD_VAR=myPwd
</code></pre>
<p>Store the <code>.env</code> file locally or in a secure location where the rest of the team can grab it.</p>
<p>See: <a href="https://docs.docker.com/compose/environment-variables/#/the-env-file" rel="noreferrer">https://docs.docker.com/compose/environment-variables/#/the-env-file</a></p>
</div></text><author><a href="/users/1341825/theutherside">theUtherSide</a></author><comments><comment><text><span class="comment-copy">You can also do this without a .env file, if you wish. Just use the <a href="https://docs.docker.com/compose/compose-file/#environment" rel="nofollow noreferrer">environment property</a> in your docker-compose.yml file . <i>"Environment variables with only a key are resolved to their values on the machine Compose is running on, which can be helpful for secret or host-specific values."</i></span></text><author><a class="comment-user" href="/users/2929693/d-visser" title="528 reputation">D. Visser</a></author></comment><comment><text><span class="comment-copy">give this man a cookie ! :) yep this is really good practice  I just want to add that <a href="https://docs.docker.com/compose/env-file/" rel="nofollow noreferrer">docs.docker.com/compose/env-file</a>  this should work automatically but in docker compose version 2 it seems you need to declare it as described in this answer.</span></text><author><a class="comment-user" href="/users/473040/equivalent8" title="7,279 reputation">equivalent8</a></author></comment></comments></answer><answer><text><div class="post-text" itemprop="text">
<p>You should never add credentials to a container unless you're OK broadcasting the creds to whomever can download the image. In particular, doing and <code>ADD creds</code> and later <code>RUN rm creds</code> is not secure because the creds file remains in the final image in an intermediate filesystem layer. It's easy for anyone with access to the image to extract it.</p>
<p>The typical solution I've seen when you need creds to checkout dependencies and such is to use one container to build another. I.e., typically you have some build environment in your base container and you need to invoke that to build your app container. So the simple solution is to add your app source and then <code>RUN</code> the build commands. This is insecure if you need creds in that <code>RUN</code>. Instead what you do is put your source into a local directory, run (as in <code>docker run</code>) the container to perform the build step with the local source directory mounted as volume and the creds either injected or mounted as another volume. Once the build step is complete you build your final container by simply <code>ADD</code>ing the local source directory which now contains the built artifacts.</p>
<p>I'm hoping Docker adds some features to simplify all this!</p>
<p>Update: looks like the method going forward will be to have nested builds. In short, the dockerfile would describe a first container that is used to build the run-time environment and then a second nested container build that can assemble all the pieces into the final container. This way the build-time stuff isn't in the second container. This of a Java app where you need the JDK for building the app but only the JRE for running it. There are a number of proposals being discussed, best to start from <a href="https://github.com/docker/docker/issues/7115">https://github.com/docker/docker/issues/7115</a> and follow some of the links for alternate proposals.</p>
</div></text><author><a href="/users/3807231/tve">TvE</a></author><comments/></answer><answer><text><div class="post-text" itemprop="text">
<p>With <strong>Docker v1.9</strong> you can use the <strong>ARG instruction</strong> to fetch arguments passed by command line to the image on <strong>build action</strong>. Simply use the <strong>--build-arg</strong> flag. So you can avoid to keep explicit password (or other sensible information) on the Dockerfile and pass them on the fly.</p>
<p>source: <a href="https://docs.docker.com/engine/reference/commandline/build/" rel="nofollow">https://docs.docker.com/engine/reference/commandline/build/</a> <a href="http://docs.docker.com/engine/reference/builder/#arg" rel="nofollow">http://docs.docker.com/engine/reference/builder/#arg</a></p>
<p>Example:</p>
<p><strong>Dockerfile</strong></p>
<pre><code>FROM busybox
ARG user
RUN echo "user is $user"
</code></pre>
<p><strong>build image command</strong></p>
<pre><code>docker build --build-arg user=capuccino -t test_arguments -f path/to/dockerfile .
</code></pre>
<p><strong>during the build it print</strong></p>
<pre><code>$ docker build --build-arg user=capuccino -t test_arguments -f ./test_args.Dockerfile .

Sending build context to Docker daemon 2.048 kB
Step 1 : FROM busybox
 ---&gt; c51f86c28340
Step 2 : ARG user
 ---&gt; Running in 43a4aa0e421d
 ---&gt; f0359070fc8f
Removing intermediate container 43a4aa0e421d
Step 3 : RUN echo "user is $user"
 ---&gt; Running in 4360fb10d46a
**user is capuccino**
 ---&gt; 1408147c1cb9
Removing intermediate container 4360fb10d46a
Successfully built 1408147c1cb9
</code></pre>
<p>Hope it helps! Bye.</p>
</div></text><author><a href="/users/4856698/nickgnd">NickGnd</a></author><comments><comment><text><span class="comment-copy">According to <a href="https://docs.docker.com/engine/reference/builder/#arg" rel="nofollow noreferrer">Docker's ARG docs</a>: "It is not recommended to use build-time variables for passing secrets like github keys, user credentials etc"</span></text><author><a class="comment-user" href="/users/309412/lie-ryan" title="37,064 reputation">Lie Ryan</a></author></comment><comment><text><span class="comment-copy">Just wondering why Docker disrecommends to use <code>--build-arg var=secret</code> for passing a SSH private key into an image, there is no rationale documented. Can anyone explain it?</span></text><author><a class="comment-user" href="/users/2614144/henk-wiersema" title="131 reputation">Henk Wiersema</a></author></comment><comment><text><span class="comment-copy">@HenkWiersema Process information, logs and command history are insecure.  Process information is available publicly and that includes all command line parameters.  Frequently these calls end up in logs which can be public also.  It's not uncommon for an attacker to inspect information on running processes and trawl public logfiles for secrets.  Even when it's not public, it could be stored in your command history which would make it easy for someone to get secrets through a non-administrative account.</span></text><author><a class="comment-user" href="/users/1327079/tudor" title="313 reputation">tudor</a></author></comment><comment><text><span class="comment-copy">What is the recommended way to supply credentials that are needed at build time? For example, an image that needs aws s3 access to fetch a large data set that will reside inside the image?</span></text><author><a class="comment-user" href="/users/567620/ely" title="22,509 reputation">ely</a></author></comment></comments></answer><answer><text><div class="post-text" itemprop="text">
<p>While I totally agree there is no simple solution. There continues to be a single point of failure. Either the dockerfile, etcd, and so on. Apcera has a plan that looks like sidekick - dual authentication. In other words two container cannot talk unless there is a Apcera configuration rule. In their demo the uid/pwd was in the clear and could not be reused until the admin configured the linkage.  For this to work, however, it probably meant patching Docker or at least the network plugin (if there is such a thing).  </p>
</div></text><author><a href="/users/99542/richard">Richard</a></author><comments/></answer><answer><text><div class="post-text" itemprop="text">
<p>As an alternative to using environment variables, which can get messy if you have a lot of them, is to use volumes to make a directory on the host accessible in the container.</p>
<p>If you put all your credentials as files in that folder, then the container can read the files and use them as it pleases.</p>
<p>For example:</p>
<pre><code>$ echo "secret" &gt; /root/configs/password.txt
$ docker run -v /root/configs:/cfg ...

In the Docker container:

# echo Password is `cat /cfg/password.txt`
Password is secret
</code></pre>
<p>Many programs can read their credentials from a separate file, so this way you can just point the program to one of the files.</p>
</div></text><author><a href="/users/308237/malvineous">Malvineous</a></author><comments/></answer></answers></post>